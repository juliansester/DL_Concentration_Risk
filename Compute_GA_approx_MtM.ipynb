{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e56fed1e",
   "metadata": {},
   "source": [
    "  # Neural Network Training for the MtM approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9a12fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import fsolve\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.style.use('bmh')\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "from tqdm import tqdm\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport IS_misc_functions\n",
    "from IS_misc_functions import *\n",
    "from misc_functions import *\n",
    "from actuarial_training import *\n",
    "from MtM_training import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler,normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba872e97",
   "metadata": {},
   "source": [
    "### Create the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20822309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x,nr_neurons = 32,regul = 0.005):\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(nr_neurons,kernel_regularizer=regularizers.l2(regul),activation='relu',input_shape=[600]),\n",
    "        #layers.Dropout(0.3),\n",
    "        layers.Dense(nr_neurons,kernel_regularizer=regularizers.l2(regul), activation='relu'),\n",
    "        #layers.Dropout(0.3),\n",
    "        layers.Dense(nr_neurons,kernel_regularizer=regularizers.l2(regul), activation='relu'),\n",
    "        #layers.Dropout(0.3),\n",
    "        layers.Dense(nr_neurons,kernel_regularizer=regularizers.l2(regul), activation='relu'),\n",
    "        #layers.Dropout(0.3),\n",
    "        layers.Dense(1)\n",
    "      ])\n",
    "    opt1 = tf.keras.optimizers.Adam(learning_rate = 0.00005, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(loss='mse',\n",
    "                    optimizer=opt1,\n",
    "                    metrics=['mae', 'mse'])\n",
    "    scaler = StandardScaler().fit(x)\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a66c8",
   "metadata": {},
   "source": [
    "### Load the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e92feca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read Data\n",
    "def read_data(xpath,ypath):\n",
    "    df_x = pd.read_csv(xpath, header=None)\n",
    "    df_x = df_x.dropna()\n",
    "    df_x = df_x.iloc[:,1:]\n",
    "\n",
    "    df_y = pd.read_csv(ypath, header=None)\n",
    "    df_y = df_y.dropna()\n",
    "    df_y = df_y.iloc[:,1:]\n",
    "    \n",
    "    return df_x,df_y\n",
    "x,y = read_data(\"csv/X_mtm_1.csv\",\"csv/Y_mtm_1.csv\")\n",
    "for i in range(13,15):\n",
    "    x_new,y_new = read_data(\"csv/X_mtm_\"+str(i)+\".csv\",\"csv/Y_mtm_\"+str(i)+\".csv\")\n",
    "    x = pd.concat([x,x_new])\n",
    "    y = pd.concat([y,y_new])\n",
    "x_train = x.reset_index(drop = True)\n",
    "y_train = y.reset_index(drop = True)\n",
    "\n",
    "x_test, y_test = read_data(\"csv/X_mtm_test.csv\",\"csv/Y_mtm_test.csv\")\n",
    "\n",
    "# Reduce Dimension of the data\n",
    "def reduce_dim_mtm(x):\n",
    "    ELGD_new = x.iloc[:,0]\n",
    "    EAD_new = x.iloc[:,100:200]\n",
    "    rho_new = x.iloc[:,200:300]\n",
    "    c_new = x.iloc[:,300:400]\n",
    "    g_new = x.iloc[:,400:500]\n",
    "    D_new = x.iloc[:,500]\n",
    "    return pd.concat([ELGD_new,EAD_new,rho_new,c_new,g_new,D_new],axis = 1)\n",
    "\n",
    "x_train_small = reduce_dim_mtm(x_train)\n",
    "x_test_small = reduce_dim_mtm(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df9ee0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = pd.read_csv(\"transition_matrix_SP.csv\",delimiter = \",\")\n",
    "SP_dict = trans_matrix_to_dict(transition_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a465b908",
   "metadata": {},
   "source": [
    "# Compute GA approx on the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d96d3d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train.iloc[1000:,:]\n",
    "# x_train = x_train.reset_index(drop=True)\n",
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81931da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GA_approx_List_Train = []\n",
    "GA_approx_List_Test = []\n",
    "\n",
    "# Training set\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    LGD_Vector = np.array(x_train.iloc[i,:100])\n",
    "    EAD_Vector = np.array(x_train.iloc[i,100:200])\n",
    "    rho_Vector = np.array(x_train.iloc[i,200:300])\n",
    "    c_vector = np.array(x_train.iloc[i,300:400])\n",
    "    g_Vector = np.array(x_train.iloc[i,400:500]).astype(int)\n",
    "    D_vector = np.array(x_train.iloc[i,500:])\n",
    "    \n",
    "    GA_approx_List_Train.append(GA_GM(PD = 0, ELGD =LGD_Vector[LGD_Vector>0],\n",
    "                                   A = EAD_Vector[EAD_Vector>0], M= np.array([1]*len(EAD_Vector>0)),\n",
    "                      q=0.999,        \n",
    "                     r = r_nelson,\n",
    "                     T=1,\n",
    "                     g= np.array(g_Vector[g_Vector>0]),\n",
    "                     trans_prob=SP_dict[\"trans_prob\"],#N times S matrix\n",
    "                     psi = 0.4, # Market Sharpe Ratio,\n",
    "                     rho = rho_Vector[EAD_Vector>0],\n",
    "                     c = c_vector[EAD_Vector>0],\n",
    "                    nu =0.25,               \n",
    "                     S = S, # Number of States of Rating\n",
    "                     default_only = False,\n",
    "                      LGD_constant = False))\n",
    "#Test set\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    LGD_Vector = np.array(x_test.iloc[i,:100])\n",
    "    EAD_Vector = np.array(x_test.iloc[i,100:200])\n",
    "    rho_Vector = np.array(x_test.iloc[i,200:300])\n",
    "    c_vector = np.array(x_test.iloc[i,300:400])\n",
    "    g_Vector = np.array(x_test.iloc[i,400:500]).astype(int)\n",
    "    D_vector = np.array(x_test.iloc[i,500:])\n",
    "    \n",
    "    GA_approx_List_Test.append(GA_GM(PD = 0, ELGD =LGD_Vector[LGD_Vector>0],\n",
    "                                   A = EAD_Vector[EAD_Vector>0], M= D_vector[EAD_Vector>0],\n",
    "                      q=0.999,        \n",
    "                     r = r_nelson,\n",
    "                     T=1,\n",
    "                     g= np.array(g_Vector[g_Vector>0]),\n",
    "                     trans_prob=SP_dict[\"trans_prob\"],#N times S matrix\n",
    "                     psi = 0.4, # Market Sharpe Ratio,\n",
    "                     rho = rho_Vector[EAD_Vector>0],\n",
    "                     c = c_vector[EAD_Vector>0],\n",
    "                    nu =0.25,               \n",
    "                     S = S, # Number of States of Rating\n",
    "                     default_only = False,\n",
    "                      LGD_constant = False))\n",
    "\n",
    "    \n",
    "pd.DataFrame(GA_approx_List_Train).to_csv(\"csv/X_Train_act_MtM_2.csv\")\n",
    "pd.DataFrame(GA_approx_List_Test).to_csv(\"csv/X_Test_MtM_approx.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
